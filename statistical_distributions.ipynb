{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction (On Site)\n",
    "\n",
    "In this lesson Greg Damico introduces statistical distributions. Sampling will be explained as it is related to a population, as well as the differences between discrete and continuous random variables, PMF’s, PDF’s, and CDF’s. Topics covered in this lecture include: Sampling, inferential statistics, statistical distributions, probability distribution, common distributions, uniform distribution, discrete distribution, bernoulli distribution, binomial distribution, continuous distribution, mass functions, density functions, cumulative distribution\n",
    "\n",
    "The repository for this lecture can be found here - [Statistical Distributions: Density Functions](!https://github.com/flatiron-school/ds-statistical_distributions-nbz32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Objectives\" data-toc-modified-id=\"Objectives-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Objectives</a></span></li><li><span><a href=\"#First-Steps:-Sampling\" data-toc-modified-id=\"First-Steps:-Sampling-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>First Steps: Sampling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Our-View-of-The-World-Isn't-Perfect\" data-toc-modified-id=\"Our-View-of-The-World-Isn't-Perfect-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Our View of The World Isn't Perfect</a></span></li><li><span><a href=\"#Solutions?\" data-toc-modified-id=\"Solutions?-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Solutions?</a></span><ul class=\"toc-item\"><li><span><a href=\"#Observe-the-Whole-Population\" data-toc-modified-id=\"Observe-the-Whole-Population-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Observe the Whole Population</a></span></li><li><span><a href=\"#We-Sample-and-Infer-the-Population's-Distribution\" data-toc-modified-id=\"We-Sample-and-Infer-the-Population's-Distribution-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>We Sample and Infer the Population's Distribution</a></span></li></ul></li><li><span><a href=\"#Going-Forward\" data-toc-modified-id=\"Going-Forward-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Going Forward</a></span></li></ul></li><li><span><a href=\"#Probability-Distributions\" data-toc-modified-id=\"Probability-Distributions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Probability Distributions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Discrete-Distributions\" data-toc-modified-id=\"Discrete-Distributions-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Discrete Distributions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Examples-of-Discrete-Distributions\" data-toc-modified-id=\"Examples-of-Discrete-Distributions-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Examples of Discrete Distributions</a></span></li></ul></li><li><span><a href=\"#Continuous-Distributions\" data-toc-modified-id=\"Continuous-Distributions-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Continuous Distributions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Examples-of-Continuous-Distributions\" data-toc-modified-id=\"Examples-of-Continuous-Distributions-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Examples of Continuous Distributions</a></span></li></ul></li></ul></li><li><span><a href=\"#PMF:-Probability-Mass-Function\" data-toc-modified-id=\"PMF:-Probability-Mass-Function-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>PMF: Probability Mass Function</a></span><ul class=\"toc-item\"><li><span><a href=\"#Uniform-Distribution\" data-toc-modified-id=\"Uniform-Distribution-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Uniform Distribution</a></span></li></ul></li><li><span><a href=\"#PDF:-Probability-Density-Function\" data-toc-modified-id=\"PDF:-Probability-Density-Function-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>PDF: Probability Density Function</a></span><ul class=\"toc-item\"><li><span><a href=\"#Describing-the-PDF\" data-toc-modified-id=\"Describing-the-PDF-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Describing the PDF</a></span></li></ul></li><li><span><a href=\"#CDF:-Cumulative-Distribution-Function\" data-toc-modified-id=\"CDF:-Cumulative-Distribution-Function-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>CDF: Cumulative Distribution Function</a></span><ul class=\"toc-item\"><li><span><a href=\"#Some-Things-to-Be-Aware-Of\" data-toc-modified-id=\"Some-Things-to-Be-Aware-Of-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Some Things to Be Aware Of</a></span></li><li><span><a href=\"#Example:-Using-CDF-&amp;-comparison-to-PDF\" data-toc-modified-id=\"Example:-Using-CDF-&amp;-comparison-to-PDF-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Example: Using CDF &amp; comparison to PDF</a></span></li></ul></li><li><span><a href=\"#Exercises\" data-toc-modified-id=\"Exercises-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Exercises</a></span><ul class=\"toc-item\"><li><span><a href=\"#Order-Totals-CDF-&amp;-PDF\" data-toc-modified-id=\"Order-Totals-CDF-&amp;-PDF-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Order Totals CDF &amp; PDF</a></span></li><li><span><a href=\"#Order-Totals-Observations\" data-toc-modified-id=\"Order-Totals-Observations-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Order Totals Observations</a></span></li></ul></li><li><span><a href=\"#Level-Up:-Details-on-Expected-Value-and-Variance\" data-toc-modified-id=\"Level-Up:-Details-on-Expected-Value-and-Variance-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Level Up: Details on Expected Value and Variance</a></span><ul class=\"toc-item\"><li><span><a href=\"#For-PMF---Discrete-Values\" data-toc-modified-id=\"For-PMF---Discrete-Values-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>For PMF - Discrete Values</a></span><ul class=\"toc-item\"><li><span><a href=\"#Expected-Value/Mean\" data-toc-modified-id=\"Expected-Value/Mean-8.1.1\"><span class=\"toc-item-num\">8.1.1&nbsp;&nbsp;</span>Expected Value/Mean</a></span></li><li><span><a href=\"#Variance/Standard-Deviation\" data-toc-modified-id=\"Variance/Standard-Deviation-8.1.2\"><span class=\"toc-item-num\">8.1.2&nbsp;&nbsp;</span>Variance/Standard Deviation</a></span></li></ul></li><li><span><a href=\"#For-PDF---Continuous-Values\" data-toc-modified-id=\"For-PDF---Continuous-Values-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>For PDF - Continuous Values</a></span></li></ul></li><li><span><a href=\"#Level-Up:-CDF-Use-Cases\" data-toc-modified-id=\"Level-Up:-CDF-Use-Cases-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Level Up: CDF Use Cases</a></span><ul class=\"toc-item\"><li><span><a href=\"#Quickly-identify-key-values\" data-toc-modified-id=\"Quickly-identify-key-values-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>Quickly identify key values</a></span></li><li><span><a href=\"#Outliers-can-be-more-obvious\" data-toc-modified-id=\"Outliers-can-be-more-obvious-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>Outliers can be more obvious</a></span></li><li><span><a href=\"#Identifying-clusters\" data-toc-modified-id=\"Identifying-clusters-9.3\"><span class=\"toc-item-num\">9.3&nbsp;&nbsp;</span>Identifying clusters</a></span></li><li><span><a href=\"#Relative-easy-to-view-multiple-distributions\" data-toc-modified-id=\"Relative-easy-to-view-multiple-distributions-9.4\"><span class=\"toc-item-num\">9.4&nbsp;&nbsp;</span>Relative easy to view multiple distributions</a></span></li></ul></li><li><span><a href=\"#Level-Up:-Skewness\" data-toc-modified-id=\"Level-Up:-Skewness-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Level Up: Skewness</a></span></li><li><span><a href=\"#Level-Up:-Kurtosis\" data-toc-modified-id=\"Level-Up:-Kurtosis-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Level Up: Kurtosis</a></span></li><li><span><a href=\"#Level-Up:-Transforming-Data\" data-toc-modified-id=\"Level-Up:-Transforming-Data-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Level Up: Transforming Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Root-Transformations\" data-toc-modified-id=\"Root-Transformations-12.1\"><span class=\"toc-item-num\">12.1&nbsp;&nbsp;</span>Root Transformations</a></span></li><li><span><a href=\"#Logarithmic-Transformations\" data-toc-modified-id=\"Logarithmic-Transformations-12.2\"><span class=\"toc-item-num\">12.2&nbsp;&nbsp;</span>Logarithmic Transformations</a></span></li><li><span><a href=\"#Power-Transformations\" data-toc-modified-id=\"Power-Transformations-12.3\"><span class=\"toc-item-num\">12.3&nbsp;&nbsp;</span>Power Transformations</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* Explain how sampling is related to its related population\n",
    "* Describe the difference between discrete and continuous random variables\n",
    "* Describe the difference between PMFs, PDFs, and CDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# First Steps: Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Before we get into our main topic of probability distributions, it'll help to first understand the concept of **sampling**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Our View of The World Isn't Perfect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We don't have _perfect_ information; life doesn't have an answer key\n",
    "\n",
    "\n",
    "![no answer in the back of the book meme](images/no-answers-in-back-of-book.jpeg)\n",
    "\n",
    "\n",
    "Ideally, we want to have all the details of a whole group. But as you can guess, that's not always feasible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**🧠 Knowledge Check**: What are some reasons we sometimes _can't_ observe the whole group?\n",
    "<details>\n",
    "<ul>\n",
    "    <li>Expensive</li>\n",
    "    <li>Unrealistic</li>\n",
    "    <li>We don't need it to gain insights!</li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Solutions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's use an example scenario to think about how we can approach this. Let's say we would like to know the ages of students at Flatiron School. \n",
    "\n",
    "Picture what this might look like. How would you describe the population of students' ages?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> **Key Terms**\n",
    ">\n",
    "> We define the **population** as the whole group we're interested in. We abstract this to the population being the whole set of _possible outcomes_.\n",
    "> \n",
    "> And when we \"pick\" a student (or students), we say we have (randomly) _sampled_ over the population. We call this subset of \"picked\" individuals/outcomes from the population a **sample**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Well, if we knew what the **population** (all the Flatiron students) looked like, we could probably get an idea of what the likely age is of a _randomly_ picked one from the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can describe the \"look\" of the population a **probability distribution**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> **Key Terms**\n",
    "> \n",
    "> A **probability distribution** is a representation of the frequencies of potential outcomes or the percentage of time each outcome occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are a few ways to get the probability distribution, even if it's only approximate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Observe the Whole Population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This might seem like \"cheating\" but sometimes this is really the best way even if it's \"expensive\" (monetarily, time, or otherwise). Sometimes this has already been done for us and we can use those results. It's important to note that sometimes the information is outdated but we can use it as approximately right. (Think how the US Census is done only every 10 years.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So in our example, we could have a _distribution_ of ages of our population. Let's say of all students were asked their age when enrolling:\n",
    "\n",
    "- $15\\%$ are under the age of $25$\n",
    "- $30\\%$ are between $25$ & $30$\n",
    "- $25\\%$ are between $30$ & $35$\n",
    "- $20\\%$ are between $35$ & $40$\n",
    "- $10\\%$ are over the age of $40$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### We Sample and Infer the Population's Distribution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Another method is to sample the population (usually randomly) and observe what the sample's distribution looks like. We can then infer what the population might look like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Suppose we ask 100 random students their ages and observe the following:\n",
    "\n",
    "- $10$ are under the age of $25$\n",
    "- $30$ are between $25$ & $30$\n",
    "- $30$ are between $30$ & $35$\n",
    "- $15$ are between $35$ & $40$\n",
    "- $15$ are over the age of $40$\n",
    "\n",
    "Then we can guess that our population is similar to this distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "How similar? Well, that can be a tough question and is part of _inferential statistics_ where we make predictions based on our observations/data.  We'll  be going into more detail about this in the near future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Going Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Today, we're going to focus on how we can describe probability distributions. This will give us a tool set whether we're talking about a sample or an established population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> **Aside - Use a Mathematical Model as a Proxy to the Population's Distribution**\n",
    "> \n",
    "> If we know what a population distribution _should_ look, we can mathematically  define a model that would fill-in for our population.\n",
    "> \n",
    "> This is analogous to something like using a perfect circle to approximate a car's tire. Is it exactly the same? No, there are some deviations from the circle but it's close enough for many applications.\n",
    "> \n",
    "> There are many other _parametric probability distributions_ which can be described mathematically and can be very convenient for us. We won't focus on this now, but know that is another use case of probability distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](images/distributions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will learn about a variety of different probability distributions, but before we do so, we need to establish the difference between **discrete** and **continuous** distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Discrete Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "With discrete distributions, you can only get certain specific values, not all values in a range.  Take, for example, a roll of a single six-sided die. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](images/uniform.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are 6 possible outcomes of the roll. As you see on the PMF plot, the bars which represent probability do not touch, suggesting non-integer numbers between 1 and 6 are not possible results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Examples of Discrete Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- **Uniform Distribution**\n",
    "    - Occurs when all possible outcomes are equally likely.\n",
    "- **Bernoulli Distribution**\n",
    "    - Represents the probability of success for a certain experiment (binary outcome).\n",
    "- **Binomial Distribution**\n",
    "    - Represents the probability of observing a specific number of successes (Bernoulli trials) in a specific number of trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Continuous Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "With a continuous distribution, you can expect to get any value within a range. Think about measuring the length of something. The reported measurement can always be more or less precise.\n",
    "\n",
    "![](images/pdf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Examples of Continuous Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- **Continuous Uniform**\n",
    "- **Normal or Gaussian**\n",
    "- **Exponential**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# PMF: Probability Mass Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The **probability mass function (pmf)** for a random variable gives, at any value $k$, the probability that the random variable takes the value $k$. Suppose, for example, that I have a jar full of lottery balls containing:\n",
    "- 50 \"1\"s,\n",
    "- 25 \"2\"s,\n",
    "- 15 \"3\"s,\n",
    "- 10 \"4\"s\n",
    "\n",
    "We then represent this function in a plot like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# For each number, we calculate the probability that pull it from the jar by dividing\n",
    "\n",
    "numbers = range(1, 5)\n",
    "counts = [50, 25, 15, 10]\n",
    "\n",
    "# calculate the probs by dividing each count by the total number of balls.\n",
    "\n",
    "probs = [count/sum(counts) for count in counts]\n",
    "\n",
    "lotto_dict = {number: prob for number, prob in zip(numbers, probs)}\n",
    "lotto_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot here!\n",
    "\n",
    "x = list(lotto_dict.keys())\n",
    "y = list(lotto_dict.values())\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "ax.plot(x, y, 'bo', ms=8, label='lotto pmf')\n",
    "ax.vlines(x, 0, y, 'r', lw=5)\n",
    "ax.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Uniform Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The uniform distribution describes a set of discrete outcomes whose probabilities are all equally likely.\n",
    "\n",
    "A common example is the roll of a die.  \n",
    "\n",
    "The pmf of a discrete uniform distribution is simply:\n",
    "\n",
    "$ f(x)=\\frac{1}{n} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# expected value for the roll of a 12-sided die\n",
    "\n",
    "expected_value = sum([1/12 * n for n in range(1, 13)])\n",
    "print(f'Expected value: {expected_value}')\n",
    "\n",
    "# variance for a roll of a 12-sided die\n",
    "\n",
    "variance = sum([1/12 * (n - expected_value)**2 for n in range(1, 13)])\n",
    "print(f'Variance: {variance}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# PDF: Probability Density Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Probability density functions are similar to PMFs, in that they describe the probability of a result within a range of values. But where PMFs are appropriate for discrete variables and so can be descibed with barplots, PDFs are smooth curves that describe continuous random variables.  \n",
    "\n",
    "![](images/pdf_temp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can think of a PDF as a bunch of bars of probabilities getting smaller and smaller until each neighbor is indistinguishable from its neighbor.\n",
    "\n",
    "It is then intuitive that you cannot calculate expected value and variance in the same way as we did with PMFs.  Instead, we have to integrate over the entirety of the curve to calculate the expected value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](images/pdf_inter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Describing the PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Instead of calculating the mean and standard deviation by hand, we will rather get familiar with how they affect the shape of our PDF.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The mean of our PDF affects where it is centered on the x-axis.  In `numpy` and `stats`, mean is denoted by the \"loc\" parameter.\n",
    "\n",
    "The two plots below have the same shape, but different centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "mean = 0\n",
    "z_curve = np.linspace(stats.norm(mean, 1).ppf(0.01),\n",
    "             stats.norm(mean, 1).ppf(0.99), 100)\n",
    "ax.plot(z_curve, stats.norm(mean, 1).pdf(z_curve),\n",
    "     'r-', lw=5, alpha=0.6, label='z_curve')\n",
    "\n",
    "mean = 1\n",
    "z_curve = np.linspace(stats.norm(mean, 1).ppf(0.01),\n",
    "             stats.norm(mean, 1).ppf(0.99), 100)\n",
    "ax.plot(z_curve, stats.norm(mean, 1).pdf(z_curve),\n",
    "     'b-', lw=5, alpha=0.6, label='norm pdf')\n",
    "\n",
    "ax.set_title(\"Two distributions differing in mean\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The variance of our plots describes how closely the points are gathered around the mean.  Low variance means tight and skinny, high variance short and wide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "mean = 1\n",
    "var = 1\n",
    "z_curve = np.linspace(stats.norm(mean, var).ppf(0.01),\n",
    "             stats.norm(mean, var).ppf(0.99), 100)\n",
    "ax.plot(z_curve, stats.norm(mean, var).pdf(z_curve),\n",
    "     'r-', lw=5, alpha=0.6, label='z_curve')\n",
    "\n",
    "mean = 1\n",
    "var = 3\n",
    "z_curve = np.linspace(stats.norm(mean, var).ppf(0.01),\n",
    "             stats.norm(mean, var).ppf(0.99), 100)\n",
    "ax.plot(z_curve, stats.norm(mean, var).pdf(z_curve),\n",
    "     'b-', lw=5, alpha=0.6, label='norm pdf')\n",
    "\n",
    "ax.set_title(\"Two distributions differing in variance\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# CDF: Cumulative Distribution Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](images/cdf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The cumulative distribution function describes the probability that your result will be of a value equal to or below a certain value. It can apply to both discrete or continuous functions.\n",
    "\n",
    "For the scenario above, the CDF would describe the probability of drawing a ball equal to or below a certain number.  \n",
    "\n",
    "In order to create the CDF from a sample, we:\n",
    "- align the values from least to greatest\n",
    "- for each value, count the number of values that are less than or equal to the current value\n",
    "- divide that count by the total number of values\n",
    "\n",
    "The CDF of the Lotto example plots how likely we are to get a ball less than or equal to a given example. \n",
    "\n",
    "Let's create the CDF for our Lotto example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# align the values\n",
    "\n",
    "lotto_dict = {0:0, 1:50, 2:25, 3:15, 4:10}\n",
    "values = list(lotto_dict.keys())\n",
    "\n",
    "# count the number of values that are less than\n",
    "# or equal to the current value\n",
    "\n",
    "count_less_than_equal = np.cumsum(list(lotto_dict.values()))\n",
    "\n",
    "# divide by total number of values\n",
    "prob_less_than_or_equal = count_less_than_equal/sum(lotto_dict.values()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(values, prob_less_than_or_equal, 'bo', ms=8, label='lotto pdf')\n",
    "for i in range(0, 5):\n",
    "    ax.hlines(prob_less_than_or_equal[i], i,i+1, 'r', lw=5,)\n",
    "for i in range(0, 4):\n",
    "    ax.vlines(i+1, prob_less_than_or_equal[i+1],\n",
    "              prob_less_than_or_equal[i], linestyles='dotted')\n",
    "ax.legend(loc='best' )\n",
    "ax.set_ylim(0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Some Things to Be Aware Of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- For continuous random variables, obtaining probabilities for observing a specific outcome is not possible \n",
    "- Be careful with interpretation of PDF\n",
    "\n",
    "We can use the CDF to learn the probability that a variable will be less than or equal to a given value.\n",
    "\n",
    "Typically, you'll see something like this equation associated with the CDF:\n",
    "\n",
    "$$F(x) = P(X\\leq x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Example: Using CDF & comparison to PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Consider the following normal distributions of heights (more on the normal distribution below).\n",
    "\n",
    "The PDF and the CDF look like so:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "r = sorted(stats.norm.rvs(loc=67, scale=4, size=1000))\n",
    "r_cdf = stats.norm.cdf(r, loc=67, scale=4)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.kdeplot(r, ax=ax1, shade=True)\n",
    "ax1.set_title('PDF of Height in US')\n",
    "\n",
    "ax2.plot(r, r_cdf, color='g')\n",
    "ax2.set_title('CDF of Height in the US');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If we provide `numpy` with the underlying parameters of our distribution, we can calculate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# the probability that a value falls below a specified value\n",
    "\n",
    "r = stats.norm(67, 4)\n",
    "r.cdf(73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# the probability that a value falls between two specified values\n",
    "\n",
    "r = stats.norm(67, 4)\n",
    "r.cdf(75) - r.cdf(67)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can also calculate the value associated with a specfic percentile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "r.ppf(0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Order Totals CDF & PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Imagine that an online clothing business gets orders with totals that are normally distributed with an average of \\\\$95 and a standard deviation of \\\\$18. **Graph the PDF and CDF** for the orders for this business. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Order Totals Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "After graphing, **write 1-3 observations** about the distributions of order totals based on these graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Your Observations**\n",
    "\n",
    "Observation 1: \n",
    "\n",
    "Observation 2: \n",
    "\n",
    "Observation 3:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Level Up: Details on Expected Value and Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## For PMF - Discrete Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Expected Value/Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The expected value, or the mean, describes the 'center' of the distribution (you may hear this called the first moment).  The 'center' refers loosely to the middle-values of a distribution, and is measured more precisely by notions like the mean, the median, and the mode.\n",
    "\n",
    "For a discrete distribution, working from the vantage point of a collected sample of n data points:\n",
    "\n",
    "mean = $\\Large\\mu = \\frac{\\Sigma^n_{i = 1}x_i}{n}$\n",
    "\n",
    "If we are working from the vantage point of known probabilities, the mean is referred to as the expected value. The expected value of a discrete distribution is the weighted sum of all values of x, where the weight is their probability.\n",
    " \n",
    "The expected value of the Lotto example is:\n",
    "${\\displaystyle \\operatorname {E} [X]= \\Sigma^n_{i=1}p(x_i)x_i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Variance/Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Variance describes the spread of the data (it is also referred to as the second moment).  The 'spread' refers loosely to how far away the more extreme values are from the center.\n",
    "\n",
    "Standard deviation is the square root of variance, and effectively measures the *average distance away from the mean*.\n",
    "\n",
    "From the standpoint of a sample, the variance of a discrete distribution of n data points is:\n",
    "\n",
    "std = $\\Large\\sigma = \\sqrt{\\frac{\\Sigma^n_{i = 1}(x_i - \\mu)^2}{n}}$\n",
    "\n",
    "\n",
    "Variance is the expectation of the squared deviation of a random variable from its mean.\n",
    "\n",
    "For our Lotto PMF, that means:\n",
    "\n",
    " $ \\Large E((X-\\mu)^2) = \\sigma^2 = \\Sigma^n_{i=1}p(x_i)(x_i - \\mu)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## For PDF - Continuous Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](images/exp_v_pdf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Level Up: CDF Use Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You might look at the CDF and wonder if it's a shadow of my beloved histogram. But there are some good use cases for this way of visualizing the CDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# First let's define some data\n",
    "domain_x = np.linspace(-1,1,100)\n",
    "norm_dist = stats.norm.rvs(0,0.3,domain_x.shape)\n",
    "norm_dist.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Quickly identify key values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Finding features like the median, minimum, maximum, and quartiles are easy to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f,(ax_pdf,ax_cdf) = plt.subplots(nrows=1,ncols=2,figsize=(12,4))\n",
    "\n",
    "###### Histogram (PDF)\n",
    "ax_pdf = sns.histplot(x=norm_dist, ax=ax_pdf, alpha=0.4)\n",
    "# You can also see the PDF if you want\n",
    "# ax_pdf = sns.kdeplot(x=out, cumulative=False, ax=ax_pdf)\n",
    "# Median\n",
    "ax_pdf.vlines(\n",
    "    x=np.median(norm_dist),\n",
    "    ymin=0,\n",
    "    ymax=10,\n",
    "    linestyles='--',\n",
    "    color='red'      \n",
    ")\n",
    "# 25th-percentile\n",
    "ax_pdf.vlines(\n",
    "    x=np.quantile(norm_dist, 0.25),\n",
    "    ymin=0,\n",
    "    ymax=10,\n",
    "    linestyles='--',\n",
    "    color='purple'      \n",
    ")\n",
    "# 75th-percentile\n",
    "ax_pdf.vlines(\n",
    "    x=np.quantile(norm_dist, 0.75),\n",
    "    ymin=0,\n",
    "    ymax=10,\n",
    "    linestyles='--',\n",
    "    color='purple'      \n",
    ")\n",
    "\n",
    "###### CDF\n",
    "ax_cdf = sns.kdeplot(x=norm_dist, cumulative=True, ax=ax_cdf)\n",
    "# Median\n",
    "ax_cdf.hlines(\n",
    "    y=0.5,\n",
    "    xmin=-1,\n",
    "    xmax=1,\n",
    "    linestyles='--',\n",
    "    color='red'\n",
    ")\n",
    "# 25th-percentile\n",
    "ax_cdf.hlines(\n",
    "    y=0.25,\n",
    "    xmin=-1,\n",
    "    xmax=1,\n",
    "    linestyles='--',\n",
    "    color='purple'\n",
    ")\n",
    "# 75th-percentile\n",
    "ax_cdf.hlines(\n",
    "    y=0.75,\n",
    "    xmin=-1,\n",
    "    xmax=1,\n",
    "    linestyles='--',\n",
    "    color='purple'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Outliers can be more obvious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Visualizations with outliers can be a little tricky. Take a look at your histogram. With outliers, it might be identified but can distort our focus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Add an outlier\n",
    "norm_with_outliers = np.append(norm_dist, 5*np.abs(np.random.randn(5)))\n",
    "norm_with_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f,(ax0,ax1) = plt.subplots(1,2, figsize=(12,4))\n",
    "# Showing the outliers\n",
    "sns.histplot(x=norm_with_outliers, alpha=0.4, ax=ax0)\n",
    "# Ignoring outliers\n",
    "ax1=sns.histplot(x=norm_with_outliers, alpha=0.4, ax=ax1)\n",
    "ax1.set_xlim(right=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In a worst-case, you might not notice the outliers because it gets swallowed up due by a bin because of the number of bins or bin width parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now using a CDF, it can be a lot easier to identify when there is an extreme value even if we scale the $x$-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f,(ax0,ax1) = plt.subplots(1,2, figsize=(12,4))\n",
    "# Showing the outliers\n",
    "ax0 = sns.kdeplot(x=norm_with_outliers, cumulative=True, ax=ax0)\n",
    "ax0.hlines(1,xmin=-1,xmax=3,color='red',linestyles='--')\n",
    "# Ignoring outliers\n",
    "ax1 = sns.kdeplot(x=norm_with_outliers, cumulative=True, ax=ax1)\n",
    "ax1.hlines(1,xmin=-1,xmax=1,color='red',linestyles='--')\n",
    "ax1.set_xlim(right=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Identifying clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Typically not hard with a histogram. But you can also see it in CDFs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "domain_x = np.linspace(-1,1,100)\n",
    "norm_dist0 = stats.norm.rvs(0,0.3,domain_x.shape)\n",
    "norm_dist1 = stats.norm.rvs(2,0.2,domain_x.shape)\n",
    "two_dist = np.append(norm_dist0,norm_dist1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f,(ax0,ax1,ax2) = plt.subplots(3,2, figsize=(12,12))\n",
    "# Histogram\n",
    "ax=sns.histplot(x=norm_dist0, alpha=0.4, ax=ax0[0])\n",
    "ax.set_xlim(-1,3.5)\n",
    "ax=sns.histplot(x=norm_dist1, alpha=0.4, ax=ax1[0])\n",
    "ax.set_xlim(-1,3.5)\n",
    "ax=sns.histplot(x=two_dist, alpha=0.4, ax=ax2[0])\n",
    "ax.set_xlim(-1,3.5)\n",
    "\n",
    "# CDF\n",
    "ax=sns.kdeplot(x=norm_dist0, alpha=0.4, ax=ax0[1], cumulative=True)\n",
    "ax.set_xlim(-1,3.5)\n",
    "ax=sns.kdeplot(x=norm_dist1, alpha=0.4, ax=ax1[1], cumulative=True)\n",
    "ax.set_xlim(-1,3.5)\n",
    "ax=sns.kdeplot(x=two_dist, alpha=0.4, ax=ax2[1], cumulative=True)\n",
    "ax.set_xlim(-1,3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Relative easy to view multiple distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "norm_dist0 = stats.norm.rvs(0,0.3,domain_x.shape)\n",
    "norm_dist1 = stats.norm.rvs(0,0.2,domain_x.shape)\n",
    "norm_dist2 = stats.norm.rvs(0.3,0.2,domain_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f,(ax0,ax1) = plt.subplots(2,1, figsize=(12,12))\n",
    "# Histogram\n",
    "ax=sns.histplot(x=norm_dist0, alpha=0.4, ax=ax0, color='red')\n",
    "ax=sns.histplot(x=norm_dist1, alpha=0.4, ax=ax0, color='yellow')\n",
    "ax=sns.histplot(x=norm_dist2, alpha=0.4, ax=ax0, color='blue')\n",
    "\n",
    "# CDF\n",
    "ax=sns.kdeplot(x=norm_dist0, alpha=0.4, ax=ax1, cumulative=True, color='red')\n",
    "ax=sns.kdeplot(x=norm_dist1, alpha=0.4, ax=ax1, cumulative=True, color='yellow')\n",
    "ax=sns.kdeplot(x=norm_dist2, alpha=0.4, ax=ax1, cumulative=True, color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Level Up: Skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Probability distributions can have skew, meaning they have more mass further from the mean on one side of the distribution than another. A skew of zero is perfectly symmetrical about the mean.   \n",
    "\n",
    "![skew](images/skew.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# We can check skewness with scipy\n",
    "\n",
    "z_curve = np.random.normal(0, 1, 1000)\n",
    "print(stats.skew(z_curve))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Level Up: Kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![kurtosis](images/kurtosis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Level Up: Transforming Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We may want to transform our skewed data to make it approach symmetry.\n",
    "\n",
    "Common transformations of this data include "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Root Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- $x \\rightarrow\\sqrt[n]{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Logarithmic Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- $x \\rightarrow\\log_n{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Power Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- $x\\rightarrow x^n$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
